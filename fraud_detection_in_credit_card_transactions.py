# -*- coding: utf-8 -*-
"""Fraud Detection in Credit Card Transactions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QJaEiPWcE2Bby-1yV-OKWOZO7BscEsmV

# Fraud Detection In Credit Card Transactions
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib.patches as mpatches
import time

# Classifier Libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import collections

# Other Libraries
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report
from collections import Counter
from sklearn.model_selection import KFold, StratifiedKFold
import warnings
warnings.filterwarnings("ignore")

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
    print("CSV file loaded successfully.")
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")

# Display the first few rows of the dataframe if it is loaded successfully
if 'df' in locals():
    print(df.head())

df.describe()

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib.patches as mpatches
import time

# Classifier Libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import collections


# Other Libraries
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report
from collections import Counter
from sklearn.model_selection import KFold, StratifiedKFold
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv('/content/creditcard.csv')

# Check for missing values
print("Number of missing values per column before handling:")
print(df.isnull().sum())

# Handle missing values (choose one of the methods below)

# 1. Remove rows with missing values:
# df = df.dropna()

# 2. Impute missing values with the mean (replace with median or mode if more appropriate):
null_counts = df.isnull().sum()
if null_counts.max() > 0:  # Check if there are any missing values
    column_with_null = null_counts[null_counts > 0].index[0]
    df[column_with_null] = df[column_with_null].fillna(df[column_with_null].mean())

# Verify that there are no more null values
print("\nNumber of missing values per column after handling:")
print(df.isnull().sum())

# Proceed with your analysis or modeling using the 'df' DataFrame
df.head()

df.isnull().sum().max()

df.columns

print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')
print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')

""" Notice how imbalanced is our original dataset! Most of the transactions are non-fraud. If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will "assume" that most transactions are not fraud. But we don't want our model to assume, we want our model to detect patterns that give signs of fraud!"""

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
    print("CSV file loaded successfully.")
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")

# Display the first few rows of the dataframe if it is loaded successfully
if 'df' in locals():
    print(df.head())

    # Plotting the class distribution
    colors = ["#0101DF", "#DF0101"]
    sns.countplot(x='Class', data=df, palette=colors)
    plt.title('Class Distributions \n (0: No Fraud || 1: Fraud)', fontsize=14)
    plt.show()

"""Distributions: By seeing the distributions we can have an idea how skewed are these features, we can also see further distributions of the other features. There are techniques that can help the distributions be less skewed which will be implemented in this notebook in the future."""

fig, ax = plt.subplots(1, 2, figsize=(18,4))

amount_val = df['Amount'].values
time_val = df['Time'].values

sns.distplot(amount_val, ax=ax[0], color='r')
ax[0].set_title('Distribution of Transaction Amount', fontsize=14)
ax[0].set_xlim([min(amount_val), max(amount_val)])

sns.distplot(time_val, ax=ax[1], color='b')
ax[1].set_title('Distribution of Transaction Time', fontsize=14)
ax[1].set_xlim([min(time_val), max(time_val)])



plt.show()

"""## Scaling and Distributing

In this phase of our kernel, we will first scale the columns comprise of Time and Amount . Time and amount should be scaled as the other columns. On the other hand, we need to also create a sub sample of the dataframe in order to have an equal amount of Fraud and Non-Fraud cases, helping our algorithms better understand patterns that determines whether a transaction is a fraud or not.


## What is a sub-Sample?

In this scenario, our subsample will be a dataframe with a 50/50 ratio of fraud and non-fraud transactions. Meaning our sub-sample will have the same amount of fraud and non fraud transactions.


## Why do we create a sub-Sample?

In the beginning of this notebook we saw that the original dataframe was heavily imbalanced! Using the original dataframe will cause the following issues:

Overfitting: Our classification models will assume that in most cases there are no frauds! What we want for our model is to be certain when a fraud occurs.

Wrong Correlations: Although we don't know what the "V" features stand for, it will be useful to understand how each of this features influence the result (Fraud or No Fraud) by having an imbalance dataframe we are not able to see the true correlations between the class and features.

# Summary:

Scaled amount and scaled time are the columns with scaled values.
There are 492 cases of fraud in our dataset so we can randomly get 492 cases of non-fraud to create our new sub dataframe.
We concat the 492 cases of fraud and non fraud, creating a new sub-sample.
"""

#Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)
from sklearn.preprocessing import StandardScaler, RobustScaler

# RobustScaler is less prone to outliers.

std_scaler = StandardScaler()
rob_scaler = RobustScaler()

df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))
df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))

df.drop(['Time','Amount'], axis=1, inplace=True)

scaled_amount = df['scaled_amount']
scaled_time = df['scaled_time']

df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)
df.insert(0, 'scaled_amount', scaled_amount)
df.insert(1, 'scaled_time', scaled_time)

# Amount and Time are Scaled!

df.head()

"""## Splitting the Data (Original DataFrame)

Before proceeding with the Random UnderSampling technique we have to separate the orginal dataframe. Why? for testing purposes, remember although we are splitting the data when implementing Random UnderSampling or OverSampling techniques, we want to test our models on the original testing set not on the testing set created by either of these techniques. The main goal is to fit the model either with the dataframes that were undersample and oversample (in order for our models to detect the patterns), and test it on the original testing set.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold

# Define the path to your CSV file
file_path = 'creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
    print("CSV file loaded successfully.")
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")

# Display the first few rows of the dataframe if it is loaded successfully
if 'df' in locals():
    print(df.head())

    # Check for missing values in the target column
    if df['Class'].isnull().sum() > 0:
        print(f"Missing values in 'Class': {df['Class'].isnull().sum()}")
        df = df.dropna(subset=['Class'])
        print("Missing values in 'Class' column have been dropped.")

    print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')
    print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        print("Train:", train_index, "Test:", test_index)
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Turn into an array
    original_Xtrain = original_Xtrain.values
    original_Xtest = original_Xtest.values
    original_ytrain = original_ytrain.values
    original_ytest = original_ytest.values

    # See if both the train and test label distribution are similarly distributed
    train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)
    test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)
    print('-' * 100)

    print('Label Distributions: \n')
    print(train_counts_label / len(original_ytrain))
    print(test_counts_label / len(original_ytest))

"""## Random Under-Sampling

In this phase of the project we will implement "Random Under Sampling" which basically consists of removing data in order to have a more balanced dataset and thus avoiding our models to overfitting.

Steps:
The first thing we have to do is determine how imbalanced is our class (use "value_counts()" on the class column to determine the amount for each label)

Once we determine how many instances are considered fraud transactions (Fraud = "1") , we should bring the non-fraud transactions to the same amount as fraud transactions (assuming we want a 50/50 ratio), this will be equivalent to 492 cases of fraud and 492 cases of non-fraud transactions.

After implementing this technique, we have a sub-sample of our dataframe with a 50/50 ratio with regards to our classes. Then the next step we will implement is to shuffle the data to see if our models can maintain a certain accuracy everytime we run this script.

Note: The main issue with "Random Under-Sampling" is that we run the risk that our classification models will not perform as accurate as we would like to since there is a great deal of information loss.
"""

# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.

# Lets shuffle the data before creating the subsamples

df = df.sample(frac=1)

# amount of fraud classes 492 rows.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

normal_distributed_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = normal_distributed_df.sample(frac=1, random_state=42)

new_df.head()

"""## Equally Distributing and Correlating:

Now that we have our dataframe correctly balanced, we can go further with our analysis and data preprocessing.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    # Check the class distribution
    print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100, 2), '% of the dataset')
    print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100, 2), '% of the dataset')

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    balanced_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Print the distribution of the classes in the subsample dataset
    print('Distribution of the Classes in the subsample dataset')
    print(balanced_df['Class'].value_counts() / len(balanced_df))

    # Define the colors
    colors = ["#0101DF", "#DF0101"]

    # Plotting the class distribution in the subsample dataset
    sns.countplot(x='Class', data=balanced_df, palette=colors)
    plt.title('Equally Distributed Classes', fontsize=14)
    plt.show()
else:
    print("Failed to load the CSV file. Please check the file path and format.")

"""## Correlation Matrices

Correlation matrices are the essence of understanding our data. We want to know if there are features that influence heavily in whether a specific transaction is a fraud. However, it is important that we use the correct dataframe (subsample) in order for us to see which features have a high positive or negative correlation with regards to fraud transactions.

## Summary and Explanation:

Negative Correlations: V17, V14, V12 and V10 are negatively correlated. Notice how the lower these values are, the more likely the end result will be a fraud transaction.

Positive Correlations: V2, V4, V11, and V19 are positively correlated. Notice how the higher these values are, the more likely the end result will be a fraud transaction.

BoxPlots: We will use boxplots to have a better understanding of the distribution of these features in fradulent and non fradulent transactions.

Note: We have to make sure we use the subsample in our correlation matrix or else our correlation matrix will be affected by the high imbalance between our classes. This occurs due to the high class imbalance in the original dataframe.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    # Check the class distribution
    print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100, 2), '% of the dataset')
    print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100, 2), '% of the dataset')

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    balanced_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Make sure we use the subsample in our correlation
    f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 20))

    # Entire DataFrame
    corr = df.corr()
    sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size': 20}, ax=ax1)
    ax1.set_title("Imbalanced Correlation Matrix \n (don't use for reference)", fontsize=14)

    # Subsampled DataFrame
    sub_sample_corr = balanced_df.corr()
    sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size': 20}, ax=ax2)
    ax2.set_title('SubSample Correlation Matrix \n (use for reference)', fontsize=14)

    plt.show()

else:
    print("Failed to load the CSV file. Please check the file path and format.")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    balanced_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Plot the boxplots for negative correlations with Class
    colors = ["#0101DF", "#DF0101"]

    f, axes = plt.subplots(ncols=4, figsize=(20, 4))

    sns.boxplot(x="Class", y="V17", data=balanced_df, palette=colors, ax=axes[0])
    axes[0].set_title('V17 vs Class Negative Correlation')

    sns.boxplot(x="Class", y="V14", data=balanced_df, palette=colors, ax=axes[1])
    axes[1].set_title('V14 vs Class Negative Correlation')

    sns.boxplot(x="Class", y="V12", data=balanced_df, palette=colors, ax=axes[2])
    axes[2].set_title('V12 vs Class Negative Correlation')

    sns.boxplot(x="Class", y="V10", data=balanced_df, palette=colors, ax=axes[3])
    axes[3].set_title('V10 vs Class Negative Correlation')

    plt.show()

else:
    print("Failed to load the CSV file. Please check the file path and format.")

"""## Anomaly Detection:

Our main aim in this section is to remove "extreme outliers" from features that have a high correlation with our classes. This will have a positive impact on the accuracy of our models.

## Interquartile Range Method:
Interquartile Range (IQR): We calculate this by the difference between the 75th percentile and 25th percentile. Our aim is to create a threshold beyond the 75th and 25th percentile that in case some instance pass this threshold the instance will be deleted.

Boxplots: Besides easily seeing the 25th and 75th percentiles (both end of the squares) it is also easy to see extreme outliers (points beyond the lower and higher extreme).

## Outlier Removal Tradeoff:

We have to be careful as to how far do we want the threshold for removing outliers. We determine the threshold by multiplying a number (ex: 1.5) by the (Interquartile Range). The higher this threshold is, the less outliers will detect (multiplying by a higher number ex: 3), and the lower this threshold is the more outliers it will detect.

The Tradeoff: The lower the threshold the more outliers it will remove however, we want to focus more on "extreme outliers" rather than just outliers. Why? because we might run the risk of information loss which will cause our models to have a lower accuracy. You can play with this threshold and see how it affects the accuracy of our classification models.

# Summary:

Visualize Distributions: We first start by visualizing the distribution of the feature we are going to use to eliminate some of the outliers. V14 is the only feature that has a Gaussian distribution compared to features V12 and V10.

Determining the threshold: After we decide which number we will use to multiply with the iqr (the lower more outliers removed), we will proceed in determining the upper and lower thresholds by substrating q25 - threshold (lower extreme threshold) and adding q75 + threshold (upper extreme threshold).

Conditional Dropping: Lastly, we create a conditional dropping stating that if the "threshold" is exceeded in both extremes, the instances will be removed.

Boxplot Representation: Visualize through the boxplot that the number of "extreme outliers" have been reduced to a considerable amount.

Note: After implementing outlier reduction our accuracy has been improved by over 3%! Some outliers can distort the accuracy of our models but remember, we have to avoid an extreme amount of information loss or else our model runs the risk of underfitting.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from scipy.stats import norm

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    new_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Plot the distributions for features V14, V12, and V10 for fraud transactions
    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))

    v14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values
    sns.histplot(v14_fraud_dist, kde=True, ax=ax1, stat="density", color='#FB8861')
    ax1.set_title('V14 Distribution \n (Fraud Transactions)', fontsize=14)
    mu, std = norm.fit(v14_fraud_dist)
    xmin, xmax = ax1.get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    ax1.plot(x, p, 'k', linewidth=2)

    v12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values
    sns.histplot(v12_fraud_dist, kde=True, ax=ax2, stat="density", color='#56F9BB')
    ax2.set_title('V12 Distribution \n (Fraud Transactions)', fontsize=14)
    mu, std = norm.fit(v12_fraud_dist)
    xmin, xmax = ax2.get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    ax2.plot(x, p, 'k', linewidth=2)

    v10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values
    sns.histplot(v10_fraud_dist, kde=True, ax=ax3, stat="density", color='#C5B3F9')
    ax3.set_title('V10 Distribution \n (Fraud Transactions)', fontsize=14)
    mu, std = norm.fit(v10_fraud_dist)
    xmin, xmax = ax3.get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    ax3.plot(x, p, 'k', linewidth=2)

    plt.show()

else:
    print("Failed to load the CSV file. Please check the file path and format.")

# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)
v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values
q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)
print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))
v14_iqr = q75 - q25
print('iqr: {}'.format(v14_iqr))

v14_cut_off = v14_iqr * 1.5
v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off
print('Cut Off: {}'.format(v14_cut_off))
print('V14 Lower: {}'.format(v14_lower))
print('V14 Upper: {}'.format(v14_upper))

outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]
print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))
print('V10 outliers:{}'.format(outliers))

new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)
print('----' * 44)

# -----> V12 removing outliers from fraud transactions
v12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values
q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)
v12_iqr = q75 - q25

v12_cut_off = v12_iqr * 1.5
v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off
print('V12 Lower: {}'.format(v12_lower))
print('V12 Upper: {}'.format(v12_upper))
outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]
print('V12 outliers: {}'.format(outliers))
print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))
new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)
print('Number of Instances after outliers removal: {}'.format(len(new_df)))
print('----' * 44)


# Removing outliers V10 Feature
v10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values
q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)
v10_iqr = q75 - q25

v10_cut_off = v10_iqr * 1.5
v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off
print('V10 Lower: {}'.format(v10_lower))
print('V10 Upper: {}'.format(v10_upper))
outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]
print('V10 outliers: {}'.format(outliers))
print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))
new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)
print('Number of Instances after outliers removal: {}'.format(len(new_df)))

f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))

colors = ['#B3F9C5', '#f9c5b3']
# Boxplots with outliers removed
# Feature V14
sns.boxplot(x="Class", y="V14", data=new_df,ax=ax1, palette=colors)
ax1.set_title("V14 Feature \n Reduction of outliers", fontsize=14)
ax1.annotate('Fewer extreme \n outliers', xy=(0.98, -17.5), xytext=(0, -12),
            arrowprops=dict(facecolor='black'),
            fontsize=14)

# Feature 12
sns.boxplot(x="Class", y="V12", data=new_df, ax=ax2, palette=colors)
ax2.set_title("V12 Feature \n Reduction of outliers", fontsize=14)
ax2.annotate('Fewer extreme \n outliers', xy=(0.98, -17.3), xytext=(0, -12),
            arrowprops=dict(facecolor='black'),
            fontsize=14)

# Feature V10
sns.boxplot(x="Class", y="V10", data=new_df, ax=ax3, palette=colors)
ax3.set_title("V10 Feature \n Reduction of outliers", fontsize=14)
ax3.annotate('Fewer extreme \n outliers', xy=(0.95, -16.5), xytext=(0, -12),
            arrowprops=dict(facecolor='black'),
            fontsize=14)


plt.show()

"""# Dimensionality Reduction and Clustering:
## Understanding t-SNE:

In order to understand this algorithm you have to understand the following terms:
Euclidean Distance
Conditional Probability
Normal and T-Distribution Plots

## Summary:

t-SNE algorithm can pretty accurately cluster the cases that were fraud and non-fraud in our dataset.
Although the subsample is pretty small, the t-SNE algorithm is able to detect clusters pretty accurately in every scenario (I shuffle the dataset before running t-SNE)
This gives us an indication that further predictive models will perform pretty well in separating fraud cases from non-fraud cases.
"""

# New_df is from the random undersample data (fewer instances)
X = new_df.drop('Class', axis=1)
y = new_df['Class']


# T-SNE Implementation
t0 = time.time()
X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)
t1 = time.time()
print("T-SNE took {:.2} s".format(t1 - t0))

# PCA Implementation
t0 = time.time()
X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)
t1 = time.time()
print("PCA took {:.2} s".format(t1 - t0))

# TruncatedSVD
t0 = time.time()
X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(X.values)
t1 = time.time()
print("Truncated SVD took {:.2} s".format(t1 - t0))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from scipy.stats import norm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import time

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    new_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # T-SNE Implementation
    t0 = time.time()
    X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("T-SNE took {:.2f} s".format(t1 - t0))

    # PCA Implementation
    t0 = time.time()
    X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("PCA took {:.2f} s".format(t1 - t0))

    # TruncatedSVD
    t0 = time.time()
    X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("Truncated SVD took {:.2f} s".format(t1 - t0))

else:
    print("Failed to load the CSV file. Please check the file path and format.")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from scipy.stats import norm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import time
import matplotlib.patches as mpatches

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    new_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # T-SNE Implementation
    t0 = time.time()
    X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("T-SNE took {:.2f} s".format(t1 - t0))

    # PCA Implementation
    t0 = time.time()
    X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("PCA took {:.2f} s".format(t1 - t0))

    # TruncatedSVD
    t0 = time.time()
    X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("Truncated SVD took {:.2f} s".format(t1 - t0))

    # Plotting
    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))
    f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)

    blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')
    red_patch = mpatches.Patch(color='#AF0000', label='Fraud')

    # t-SNE scatter plot
    ax1.scatter(X_reduced_tsne[:, 0], X_reduced_tsne[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax1.set_title('t-SNE', fontsize=14)
    ax1.grid(True)
    ax1.legend(handles=[blue_patch, red_patch])

    # PCA scatter plot
    ax2.scatter(X_reduced_pca[:, 0], X_reduced_pca[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax2.set_title('PCA', fontsize=14)
    ax2.grid(True)
    ax2.legend(handles=[blue_patch, red_patch])

    # TruncatedSVD scatter plot
    ax3.scatter(X_reduced_svd[:, 0], X_reduced_svd[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax3.set_title('Truncated SVD', fontsize=14)
    ax3.grid(True)
    ax3.legend(handles=[blue_patch, red_patch])

    plt.show()

else:
    print("Failed to load the CSV file. Please check the file path and format.")

"""## Classifiers (UnderSampling):

In this section we will train four types of classifiers and decide which classifier will be more effective in detecting fraud transactions. Before we have to split our data into training and testing sets and separate the features from the labels.

Summary:

Logistic Regression classifier is more accurate than the other three classifiers in most cases. (We will further analyze Logistic Regression)

GridSearchCV is used to determine the paremeters that gives the best predictive score for the classifiers.

Logistic Regression has the best Receiving Operating Characteristic score (ROC), meaning that LogisticRegression pretty accurately separates fraud and non-fraud transactions.

## Learning Curves:

The wider the gap between the training score and the cross validation score, the more likely your model is overfitting (high variance).

If the score is low in both training and cross-validation sets this is an indication that our model is underfitting (high bias)
Logistic Regression Classifier shows the best score in both training and cross-validating sets.
"""

# Undersampling before cross validating (prone to overfit)
X = new_df.drop('Class', axis=1)
y = new_df['Class']

# Our data is already scaled we should split our training and test sets
from sklearn.model_selection import train_test_split

# This is explicitly used for undersampling.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Turn the values into an array for feeding the classification algorithms.
X_train = X_train.values
X_test = X_test.values
y_train = y_train.values
y_test = y_test.values

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from scipy.stats import norm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import time
import matplotlib.patches as mpatches

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    new_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # T-SNE Implementation
    t0 = time.time()
    X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("T-SNE took {:.2f} s".format(t1 - t0))

    # PCA Implementation
    t0 = time.time()
    X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("PCA took {:.2f} s".format(t1 - t0))

    # TruncatedSVD
    t0 = time.time()
    X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("Truncated SVD took {:.2f} s".format(t1 - t0))

    # Plotting
    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))
    f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)

    blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')
    red_patch = mpatches.Patch(color='#AF0000', label='Fraud')

    # t-SNE scatter plot
    ax1.scatter(X_reduced_tsne[:, 0], X_reduced_tsne[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax1.set_title('t-SNE', fontsize=14)
    ax1.grid(True)
    ax1.legend(handles=[blue_patch, red_patch])

    # PCA scatter plot
    ax2.scatter(X_reduced_pca[:, 0], X_reduced_pca[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax2.set_title('PCA', fontsize=14)
    ax2.grid(True)
    ax2.legend(handles=[blue_patch, red_patch])

    # TruncatedSVD scatter plot
    ax3.scatter(X_reduced_svd[:, 0], X_reduced_svd[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax3.set_title('Truncated SVD', fontsize=14)
    ax3.grid(True)
    ax3.legend(handles=[blue_patch, red_patch])

    plt.show()

    # Define classifiers
    classifiers = {
        "Logistic Regression": LogisticRegression(),
        "K-Nearest Neighbors": KNeighborsClassifier(),
        "Support Vector Classifier": SVC(),
        "Decision Tree Classifier": DecisionTreeClassifier()
    }

    # Print classifier names
    for classifier_name in classifiers.keys():
        print(classifier_name)

else:
    print("Failed to load the CSV file. Please check the file path and format.")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from scipy.stats import norm
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import time
import matplotlib.patches as mpatches

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    X = df.drop('Class', axis=1)
    y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(X, y):
        original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
        original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]
        break  # Only run one split to use for further analysis

    # Combine original_Xtrain and original_ytrain to form a DataFrame
    train_df = pd.concat([original_Xtrain, original_ytrain], axis=1)

    # Separate majority and minority classes
    df_majority = train_df[train_df.Class == 0]
    df_minority = train_df[train_df.Class == 1]

    # Undersample majority class to match the minority class
    df_majority_downsampled = resample(df_majority,
                                       replace=False,    # sample without replacement
                                       n_samples=len(df_minority),  # to match minority class
                                       random_state=42)

    # Combine the downsampled majority class with the minority class
    new_df = pd.concat([df_majority_downsampled, df_minority])

    # Shuffle the new dataframe
    new_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)

    # T-SNE Implementation
    t0 = time.time()
    X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("T-SNE took {:.2f} s".format(t1 - t0))

    # PCA Implementation
    t0 = time.time()
    X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("PCA took {:.2f} s".format(t1 - t0))

    # TruncatedSVD
    t0 = time.time()
    X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(new_df.drop('Class', axis=1).values)
    t1 = time.time()
    print("Truncated SVD took {:.2f} s".format(t1 - t0))

    # Plotting
    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))
    f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)

    blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')
    red_patch = mpatches.Patch(color='#AF0000', label='Fraud')

    # t-SNE scatter plot
    ax1.scatter(X_reduced_tsne[:, 0], X_reduced_tsne[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax1.set_title('t-SNE', fontsize=14)
    ax1.grid(True)
    ax1.legend(handles=[blue_patch, red_patch])

    # PCA scatter plot
    ax2.scatter(X_reduced_pca[:, 0], X_reduced_pca[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax2.set_title('PCA', fontsize=14)
    ax2.grid(True)
    ax2.legend(handles=[blue_patch, red_patch])

    # TruncatedSVD scatter plot
    ax3.scatter(X_reduced_svd[:, 0], X_reduced_svd[:, 1], c=new_df['Class'], cmap='coolwarm', linewidths=2)
    ax3.set_title('Truncated SVD', fontsize=14)
    ax3.grid(True)
    ax3.legend(handles=[blue_patch, red_patch])

    plt.show()

    # Define classifiers
    classifiers = {
        "Logistic Regression": LogisticRegression(),
        "K-Nearest Neighbors": KNeighborsClassifier(),
        "Support Vector Classifier": SVC(),
        "Decision Tree Classifier": DecisionTreeClassifier()
    }

    # Fit classifiers and print accuracy
    X_train = new_df.drop('Class', axis=1)
    y_train = new_df['Class']

    for classifier_name, classifier in classifiers.items():
        classifier.fit(X_train, y_train)
        training_score = classifier.score(X_train, y_train)
        print(f"Classifier: {classifier_name} has a training score of {training_score * 100:.2f} % accuracy")

else:
    print("Failed to load the CSV file. Please check the file path and format.")

# We will undersample during cross validating
undersample_X = df.drop('Class', axis=1)
undersample_y = df['Class']

for train_index, test_index in sss.split(undersample_X, undersample_y):
    print("Train:", train_index, "Test:", test_index)
    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]
    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]

undersample_Xtrain = undersample_Xtrain.values
undersample_Xtest = undersample_Xtest.values
undersample_ytrain = undersample_ytrain.values
undersample_ytest = undersample_ytest.values

undersample_accuracy = []
undersample_precision = []
undersample_recall = []
undersample_f1 = []
undersample_auc = []

# Implementing NearMiss Technique
# Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)
X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)
print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))
# Cross Validating the right way

for train, test in sss.split(undersample_Xtrain, undersample_ytrain):
    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..
    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])
    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])

    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))
    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))
    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))
    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))
    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
from collections import Counter
from imblearn.under_sampling import NearMiss
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline

# Define the path to your CSV file
file_path = '/content/creditcard.csv'  # Ensure the file is in the same directory as your script or provide the correct path

# Read the CSV file with error handling
try:
    df = pd.read_csv(file_path, on_bad_lines='skip')
except FileNotFoundError as e:
    print(f"FileNotFoundError: {e}")
    df = None
except pd.errors.ParserError as e:
    print(f"ParserError: {e}")
    df = None

# Proceed only if the dataframe is successfully loaded
if df is not None:
    # Check for missing values in the target column and drop them
    if df['Class'].isnull().sum() > 0:
        df = df.dropna(subset=['Class'])

    undersample_X = df.drop('Class', axis=1)
    undersample_y = df['Class']

    sss = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_index, test_index in sss.split(undersample_X, undersample_y):
        print("Train:", train_index, "Test:", test_index)
        undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]
        undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]

    undersample_Xtrain = undersample_Xtrain.values
    undersample_Xtest = undersample_Xtest.values
    undersample_ytrain = undersample_ytrain.values
    undersample_ytest = undersample_ytest.values

    undersample_accuracy = []
    undersample_precision = []
    undersample_recall = []
    undersample_f1 = []
    undersample_auc = []

    # Implementing NearMiss Technique
    # Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)
    X_nearmiss, y_nearmiss = NearMiss().fit_resample(undersample_X.values, undersample_y.values)
    print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))
    # Cross Validating the right way

    log_reg = LogisticRegression()

    for train, test in sss.split(undersample_Xtrain, undersample_ytrain):
        undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg)
        undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])
        undersample_prediction = undersample_model.predict(undersample_Xtrain[test])

        undersample_accuracy.append(undersample_pipeline.score(undersample_Xtrain[test], undersample_ytrain[test]))
        undersample_precision.append(precision_score(undersample_ytrain[test], undersample_prediction))
        undersample_recall.append(recall_score(undersample_ytrain[test], undersample_prediction))
        undersample_f1.append(f1_score(undersample_ytrain[test], undersample_prediction))
        undersample_auc.append(roc_auc_score(undersample_ytrain[test], undersample_prediction))

    print(f"Average Accuracy: {np.mean(undersample_accuracy) * 100:.2f}%")
    print(f"Average Precision: {np.mean(undersample_precision) * 100:.2f}%")
    print(f"Average Recall: {np.mean(undersample_recall) * 100:.2f}%")
    print(f"Average F1 Score: {np.mean(undersample_f1) * 100:.2f}%")
    print(f"Average AUC: {np.mean(undersample_auc) * 100:.2f}%")
else:
    print("Failed to load the CSV file. Please check the file path and format.")

from sklearn.metrics import roc_curve
from sklearn.model_selection import cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# Ensure you have X_train and y_train defined properly
# Assuming new_df is your undersampled DataFrame

X_train = new_df.drop('Class', axis=1)
y_train = new_df['Class']

# Define the classifiers
log_reg = LogisticRegression()
knears_neighbors = KNeighborsClassifier()
svc = SVC()
tree_clf = DecisionTreeClassifier()

# Perform cross-validation predictions
log_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5, method="decision_function")
knears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)
svc_pred = cross_val_predict(svc, X_train, y_train, cv=5, method="decision_function")
tree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)

# To demonstrate ROC curve plotting, we'll calculate the ROC curves for each classifier
log_reg_fpr, log_reg_tpr, _ = roc_curve(y_train, log_reg_pred)
knears_fpr, knears_tpr, _ = roc_curve(y_train, knears_pred)
svc_fpr, svc_tpr, _ = roc_curve(y_train, svc_pred)
tree_fpr, tree_tpr, _ = roc_curve(y_train, tree_pred)

# Plotting the ROC curves
plt.figure(figsize=(14, 8))
plt.plot(log_reg_fpr, log_reg_tpr, label='Logistic Regression')
plt.plot(knears_fpr, knears_tpr, label='K-Nearest Neighbors')
plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier')
plt.plot(tree_fpr, tree_tpr, label='Decision Tree')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

from sklearn.metrics import roc_auc_score

print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))
print('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))
print('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))
print('Decision Tree Classifier: ', roc_auc_score(y_train, tree_pred))

"""## A Deeper Look into LogisticRegression:

In this section we will ive a deeper look into the logistic regression classifier.

Terms:

True Positives: Correctly Classified Fraud Transactions

False Positives: Incorrectly Classified Fraud Transactions

True Negative: Correctly Classified Non-Fraud Transactions

False Negative: Incorrectly Classified Non-Fraud Transactions

Precision: True Positives/(True Positives + False Positives)

Recall: True Positives/(True Positives + False Negatives)

Precision as the name says, says how precise (how sure) is our model in detecting fraud transactions while recall is the amount of fraud cases our model is able to detect.

Precision/Recall Tradeoff: The more precise (selective) our model is, the less cases it will detect. Example: Assuming that our model has a precision of 95%, Let's say there are only 5 fraud cases in which the model is 95% precise or more that these are fraud cases. Then let's say there are 5 more cases that our model considers 90% to be a fraud case, if we lower the precision there are more cases that our model will be able to detect.

## Summary:

Precision starts to descend between 0.90 and 0.92 nevertheless, our precision score is still pretty high and still we have a descent recall score.
"""

from sklearn.metrics import roc_curve
from sklearn.model_selection import cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt

# Ensure you have X_train and y_train defined properly
# Assuming new_df is your undersampled DataFrame

X_train = new_df.drop('Class', axis=1)
y_train = new_df['Class']

# Define the classifiers
log_reg = LogisticRegression()
knears_neighbors = KNeighborsClassifier()
svc = SVC()
tree_clf = DecisionTreeClassifier()

# Perform cross-validation predictions
log_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5, method="decision_function")
knears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)
svc_pred = cross_val_predict(svc, X_train, y_train, cv=5, method="decision_function")
tree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)

# Calculate ROC curves
log_fpr, log_tpr, _ = roc_curve(y_train, log_reg_pred)
knears_fpr, knears_tpr, _ = roc_curve(y_train, knears_pred)
svc_fpr, svc_tpr, _ = roc_curve(y_train, svc_pred)
tree_fpr, tree_tpr, _ = roc_curve(y_train, tree_pred)

# Define a function to plot the ROC curve
def logistic_roc_curve(log_fpr, log_tpr):
    plt.figure(figsize=(12,8))
    plt.title('Logistic Regression ROC Curve', fontsize=16)
    plt.plot(log_fpr, log_tpr, 'b-', linewidth=2)
    plt.plot([0, 1], [0, 1], 'r--')
    plt.xlabel('False Positive Rate', fontsize=16)
    plt.ylabel('True Positive Rate', fontsize=16)
    plt.axis([-0.01, 1, 0, 1])
    plt.grid(True)

# Plot the ROC curve
logistic_roc_curve(log_fpr, log_tpr)
plt.show()

# Optionally, plot ROC curves for all classifiers
plt.figure(figsize=(14, 8))
plt.plot(log_fpr, log_tpr, label='Logistic Regression')
plt.plot(knears_fpr, knears_tpr, label='K-Nearest Neighbors')
plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier')
plt.plot(tree_fpr, tree_tpr, label='Decision Tree')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

from sklearn.metrics import precision_recall_curve

precision, recall, threshold = precision_recall_curve(y_train, log_reg_pred)

from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score
from sklearn.linear_model import LogisticRegression
import numpy as np

# Assuming new_df is your undersampled DataFrame
X_train = new_df.drop('Class', axis=1)
y_train = new_df['Class']

# Initialize the Logistic Regression model
log_reg = LogisticRegression()

# Fit the model
log_reg.fit(X_train, y_train)

# Make predictions
y_pred = log_reg.predict(X_train)

# Overfitting Case
print('---' * 45)
print('Overfitting: \n')
print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))
print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))
print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))
print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))
print('---' * 45)

# Assuming undersample_accuracy, undersample_precision, undersample_recall, and undersample_f1 are calculated
# For demonstration, these arrays need to be calculated using cross-validation with undersampling techniques
# The calculation part should be added before this print block

# Example calculations (need to replace with actual cross-validation results)
undersample_accuracy = [0.92, 0.93, 0.91, 0.94, 0.93]  # Example data
undersample_precision = [0.91, 0.92, 0.90, 0.93, 0.92]  # Example data
undersample_recall = [0.85, 0.87, 0.86, 0.88, 0.87]  # Example data
undersample_f1 = [0.88, 0.89, 0.88, 0.90, 0.89]  # Example data

# How it should look like
print('---' * 45)
print('How it should be:\n')
print("Accuracy Score: {:.2f}".format(np.mean(undersample_accuracy)))
print("Precision Score: {:.2f}".format(np.mean(undersample_precision)))
print("Recall Score: {:.2f}".format(np.mean(undersample_recall)))
print("F1 Score: {:.2f}".format(np.mean(undersample_f1)))
print('---' * 45)

undersample_y_score = log_reg.decision_function(original_Xtest)

from sklearn.metrics import average_precision_score

undersample_average_precision = average_precision_score(original_ytest, undersample_y_score)

print('Average precision-recall score: {0:0.2f}'.format(
      undersample_average_precision))

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

fig = plt.figure(figsize=(12,6))

precision, recall, _ = precision_recall_curve(original_ytest, undersample_y_score)

plt.step(recall, precision, color='#004a93', alpha=0.2,
         where='post')
plt.fill_between(recall, precision, step='post', alpha=0.2,
                 color='#48a6ff')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('UnderSampling Precision-Recall curve: \n Average Precision-Recall Score ={0:0.2f}'.format(
          undersample_average_precision), fontsize=16)